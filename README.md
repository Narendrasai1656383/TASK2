# TASK2
Task 2: Chat with Website Using RAG Pipeline
Overview
The goal is to implement a Retrieval-Augmented Generation (RAG) pipeline that enables interaction with structured and unstructured data extracted from websites. The system crawls, scrapes, and stores website content in a vector database for efficient similarity-based retrieval. User queries are answered accurately with responses generated by a Large Language Model (LLM).

Functional Requirements
Data Ingestion

Input: URLs or a list of target websites.
Process:
Crawl and scrape content from target websites.
Extract key textual content, metadata, and relevant fields.
Split the content into chunks for better granularity.
Convert chunks into vector embeddings using a pre-trained embedding model.
Store embeddings and metadata in a vector database for efficient retrieval.
Query Handling

Input: User's natural language question.
Process:
Convert the query into vector embeddings.
Perform a similarity search in the vector database to retrieve relevant content.
Use retrieved content with the LLM to generate a response.
Response Generation

Input: Retrieved chunks and user query.
Process:
Generate detailed responses using the LLM with context-augmented prompts.
Ensure factual accuracy by incorporating retrieved data directly into the response.
Technology Stack
Libraries/Tools:
BeautifulSoup / Scrapy (Web scraping)
FAISS (Vector database)
Sentence Transformers (Embedding model)
Selected LLM for response generation
How to Run
Install dependencies:
bash
Copy code
pip install beautifulsoup4 scrapy sentence-transformers faiss-cpu
Provide URLs or a list of target websites to scrape.
Run the script to process website content, store embeddings, and handle queries.
Example query: "What are the main features of the product listed on the website?"
Output
Accurate query-specific responses based on website content.
